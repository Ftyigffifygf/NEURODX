#!/usr/bin/env python3
"""
NeuroDx-MultiModal MONAI Deploy Application
Production-ready MONAI Deploy app for neurodegenerative disease diagnosis
"""

import logging
import os
from pathlib import Path
from typing import Dict, Any, List

import numpy as np
import torch
from monai.deploy.core import Application, DataPath, ExecutionContext, Image, InputContext, IOType, Operator, OutputContext
from monai.deploy.operators.monai_seg_inference_operator import MonaiSegInferenceOperator
from monai.transforms import (
    Compose,
    EnsureChannelFirstd,
    LoadImaged,
    Orientationd,
    ScaleIntensityRanged,
    Spacingd,
    ToTensord,
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NeuroDxPreprocessOperator(Operator):
    """
    Preprocessing operator for NeuroDx-MultiModal medical images
    Handles NIfTI and DICOM image preprocessing for neurodegenerative disease analysis
    """
    
    def __init__(self):
        super().__init__()
        self.transforms = Compose([
            LoadImaged(keys=["image"]),
            EnsureChannelFirstd(keys=["image"]),
            Orientationd(keys=["image"], axcodes="RAS"),
            Spacingd(keys=["image"], pixdim=(1.0, 1.0, 1.0), mode="bilinear"),
            ScaleIntensityRanged(
                keys=["image"],
                a_min=0,
                a_max=1000,
                b_min=0.0,
                b_max=1.0,
                clip=True
            ),
            ToTensord(keys=["image"])
        ])
    
    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):
        """Preprocess medical images for NeuroDx analysis"""
        
        logger.info("üîÑ Starting NeuroDx preprocessing...")
        
        # Get input image
        input_image = op_input.get("image")
        
        # Prepare data dictionary for MONAI transforms
        data_dict = {"image": input_image}
        
        # Apply preprocessing transforms
        try:
            processed_data = self.transforms(data_dict)
            processed_image = processed_data["image"]
            
            logger.info(f"‚úÖ Preprocessing completed. Image shape: {processed_image.shape}")
            
            # Set output
            op_output.set(processed_image, "processed_image")
            
        except Exception as e:
            logger.error(f"‚ùå Preprocessing failed: {e}")
            raise


class NeuroDxInferenceOperator(Operator):
    """
    Inference operator for NeuroDx-MultiModal SwinUNETR model
    Performs multi-modal neurodegenerative disease analysis
    """
    
    def __init__(self, model_path: str = None):
        super().__init__()
        self.model_path = model_path or "models/neurodx_swin_unetr.pth"
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
    def setup(self, context: ExecutionContext):
        """Setup the SwinUNETR model for inference"""
        
        logger.info("ü§ñ Setting up NeuroDx SwinUNETR model...")
        
        try:
            from monai.networks.nets import SwinUNETR
            
            # Initialize SwinUNETR model
            self.model = SwinUNETR(
                img_size=(96, 96, 96),
                in_channels=1,
                out_channels=4,  # Background, Hippocampus, Ventricles, Cortex
                feature_size=48,
                use_checkpoint=True
            )
            
            # Load trained weights if available
            if Path(self.model_path).exists():
                checkpoint = torch.load(self.model_path, map_location=self.device)
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    self.model.load_state_dict(checkpoint)
                logger.info(f"‚úÖ Loaded model weights from {self.model_path}")
            else:
                logger.warning(f"‚ö†Ô∏è Model weights not found at {self.model_path}, using random weights")
            
            self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"‚úÖ Model setup completed on device: {self.device}")
            
        except Exception as e:
            logger.error(f"‚ùå Model setup failed: {e}")
            raise
    
    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):
        """Perform NeuroDx inference"""
        
        logger.info("üß† Starting NeuroDx inference...")
        
        try:
            # Get preprocessed image
            processed_image = op_input.get("processed_image")
            
            # Ensure correct input format
            if isinstance(processed_image, torch.Tensor):
                input_tensor = processed_image.unsqueeze(0).to(self.device)  # Add batch dimension
            else:
                input_tensor = torch.from_numpy(processed_image).unsqueeze(0).to(self.device)
            
            logger.info(f"Input tensor shape: {input_tensor.shape}")
            
            # Perform inference
            with torch.no_grad():
                outputs = self.model(input_tensor)
                
                # Apply softmax for probability scores
                probabilities = torch.softmax(outputs, dim=1)
                
                # Get segmentation prediction
                segmentation = torch.argmax(probabilities, dim=1)
                
            # Convert to numpy for output
            segmentation_np = segmentation.cpu().numpy().squeeze()
            probabilities_np = probabilities.cpu().numpy().squeeze()
            
            # Calculate diagnostic metrics
            diagnostic_results = self._calculate_diagnostic_metrics(segmentation_np, probabilities_np)
            
            logger.info("‚úÖ Inference completed successfully")
            
            # Set outputs
            op_output.set(segmentation_np, "segmentation")
            op_output.set(probabilities_np, "probabilities")
            op_output.set(diagnostic_results, "diagnostics")
            
        except Exception as e:
            logger.error(f"‚ùå Inference failed: {e}")
            raise
    
    def _calculate_diagnostic_metrics(self, segmentation: np.ndarray, probabilities: np.ndarray) -> Dict[str, Any]:
        """Calculate diagnostic metrics from segmentation results"""
        
        # Calculate volumes for each structure
        voxel_volume = 1.0  # mm¬≥ per voxel (assuming 1mm¬≥ spacing)
        
        volumes = {
            "background": np.sum(segmentation == 0) * voxel_volume,
            "hippocampus": np.sum(segmentation == 1) * voxel_volume,
            "ventricles": np.sum(segmentation == 2) * voxel_volume,
            "cortex": np.sum(segmentation == 3) * voxel_volume
        }
        
        # Calculate confidence scores
        max_probs = np.max(probabilities, axis=0)
        confidence_score = np.mean(max_probs)
        
        # Simulate disease risk assessment based on volumes
        hippocampal_volume = volumes["hippocampus"]
        ventricular_volume = volumes["ventricles"]
        
        # Simple risk scoring (in practice, use trained models)
        alzheimer_risk = max(0.0, min(1.0, (3000 - hippocampal_volume) / 1000))
        mci_risk = max(0.0, min(1.0, (2800 - hippocampal_volume) / 800))
        
        diagnostic_results = {
            "volumes": volumes,
            "confidence_score": float(confidence_score),
            "risk_scores": {
                "alzheimer_disease": float(alzheimer_risk),
                "mild_cognitive_impairment": float(mci_risk),
                "healthy": float(1.0 - max(alzheimer_risk, mci_risk))
            },
            "recommendations": self._generate_recommendations(alzheimer_risk, mci_risk)
        }
        
        return diagnostic_results
    
    def _generate_recommendations(self, alzheimer_risk: float, mci_risk: float) -> List[str]:
        """Generate clinical recommendations based on risk scores"""
        
        recommendations = []
        
        if alzheimer_risk > 0.7:
            recommendations.extend([
                "Consider amyloid PET imaging for confirmation",
                "Neuropsychological assessment recommended",
                "Discuss with neurology specialist"
            ])
        elif mci_risk > 0.6:
            recommendations.extend([
                "Monitor cognitive function closely",
                "Consider cognitive training programs",
                "Follow-up imaging in 6-12 months"
            ])
        else:
            recommendations.extend([
                "Continue routine monitoring",
                "Maintain healthy lifestyle",
                "Regular cognitive assessments"
            ])
        
        return recommendations


class NeuroDxPostprocessOperator(Operator):
    """
    Postprocessing operator for NeuroDx results
    Formats and saves diagnostic results
    """
    
    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):
        """Postprocess and format NeuroDx results"""
        
        logger.info("üìä Starting NeuroDx postprocessing...")
        
        try:
            # Get inference results
            segmentation = op_input.get("segmentation")
            probabilities = op_input.get("probabilities")
            diagnostics = op_input.get("diagnostics")
            
            # Create comprehensive report
            report = {
                "patient_id": "PATIENT_001",  # In practice, get from input metadata
                "analysis_timestamp": context.input_dir,  # Use timestamp
                "segmentation_results": {
                    "shape": segmentation.shape,
                    "unique_labels": np.unique(segmentation).tolist(),
                    "volumes": diagnostics["volumes"]
                },
                "diagnostic_assessment": {
                    "confidence_score": diagnostics["confidence_score"],
                    "risk_scores": diagnostics["risk_scores"],
                    "primary_finding": self._get_primary_finding(diagnostics["risk_scores"]),
                    "recommendations": diagnostics["recommendations"]
                },
                "model_info": {
                    "architecture": "SwinUNETR",
                    "version": "1.0.0",
                    "framework": "MONAI Deploy"
                }
            }
            
            logger.info("‚úÖ Postprocessing completed")
            
            # Set outputs
            op_output.set(segmentation, "final_segmentation")
            op_output.set(report, "diagnostic_report")
            
        except Exception as e:
            logger.error(f"‚ùå Postprocessing failed: {e}")
            raise
    
    def _get_primary_finding(self, risk_scores: Dict[str, float]) -> str:
        """Get primary diagnostic finding"""
        max_risk = max(risk_scores.values())
        primary_condition = max(risk_scores, key=risk_scores.get)
        
        if max_risk > 0.7:
            return f"High risk for {primary_condition.replace('_', ' ')}"
        elif max_risk > 0.5:
            return f"Moderate risk for {primary_condition.replace('_', ' ')}"
        else:
            return "Low risk for neurodegenerative disease"


@Application.decorator()
class NeuroDxMultiModalApp(Application):
    """
    NeuroDx-MultiModal MONAI Deploy Application
    Complete application for neurodegenerative disease diagnosis
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # Application metadata
        self.name = "NeuroDx-MultiModal"
        self.version = "1.0.0"
        self.description = "Multi-modal diagnostic assistant for neurodegenerative diseases"
    
    def compose(self):
        """Compose the NeuroDx application workflow"""
        
        logger.info("üèóÔ∏è Composing NeuroDx-MultiModal application...")
        
        # Define operators
        preprocess_op = NeuroDxPreprocessOperator()
        inference_op = NeuroDxInferenceOperator()
        postprocess_op = NeuroDxPostprocessOperator()
        
        # Define workflow
        self.add_flow(preprocess_op, inference_op, {"processed_image": "processed_image"})
        self.add_flow(inference_op, postprocess_op, {
            "segmentation": "segmentation",
            "probabilities": "probabilities", 
            "diagnostics": "diagnostics"
        })
        
        logger.info("‚úÖ Application composition completed")


def main():
    """Main function to run NeuroDx-MultiModal application"""
    
    print("üß† NeuroDx-MultiModal MONAI Deploy Application")
    print("=" * 60)
    
    # Create and run application
    app = NeuroDxMultiModalApp()
    
    # Set input/output paths from command line or defaults
    input_path = os.environ.get("MONAI_INPUT_PATH", "input")
    output_path = os.environ.get("MONAI_OUTPUT_PATH", "output")
    
    logger.info(f"Input path: {input_path}")
    logger.info(f"Output path: {output_path}")
    
    try:
        # Run the application
        app.run(input=input_path, output=output_path)
        
        print("üéâ NeuroDx analysis completed successfully!")
        print(f"üìÅ Results saved to: {output_path}")
        
    except Exception as e:
        logger.error(f"‚ùå Application failed: {e}")
        raise


if __name__ == "__main__":
    main()