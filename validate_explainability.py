"""
Simple validation script for explainability features.

This script tests the Grad-CAM and Integrated Gradients implementations
without requiring the full configuration system.
"""

import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import sys

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Import MONAI components directly
from monai.networks.nets import SwinUNETR
import torch.nn.functional as F


class SimpleMultiTaskSwinUNETR(nn.Module):
    """Simplified multi-task SwinUNETR for testing."""
    
    def __init__(self, in_channels=4, out_channels=3, num_classes=4):
        super().__init__()
        
        # Main SwinUNETR backbone
        self.swin_unetr = SwinUNETR(
            in_channels=in_channels,
            out_channels=out_channels,
            feature_size=24
        )
        
        # Simple classification head
        self.global_avg_pool = nn.AdaptiveAvgPool3d(1)
        self.classification_head = nn.Sequential(
            nn.Linear(out_channels, 64),
            nn.ReLU(),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x):
        # Get segmentation output
        segmentation_logits = self.swin_unetr(x)
        
        # Extract features for classification (simplified)
        # Use the segmentation features as a proxy
        pooled_features = self.global_avg_pool(segmentation_logits)
        pooled_features = pooled_features.view(pooled_features.size(0), -1)
        classification_logits = self.classification_head(pooled_features)
        
        return {
            "segmentation": segmentation_logits,
            "classification": classification_logits
        }


def test_gradcam():
    """Test Grad-CAM implementation."""
    print("Testing Grad-CAM...")
    
    # Create model
    model = SimpleMultiTaskSwinUNETR()
    model.eval()
    
    # Create dummy input (larger size for SwinUNETR)
    input_tensor = torch.randn(1, 4, 96, 96, 96)
    input_tensor.requires_grad_(True)
    
    # Forward pass to get target class
    with torch.no_grad():
        outputs = model(input_tensor)
        target_class = torch.argmax(outputs["classification"], dim=1).item()
    
    print(f"Target class: {target_class}")
    
    # Simple Grad-CAM implementation
    model.zero_grad()
    
    # Forward pass
    outputs = model(input_tensor)
    class_output = outputs["classification"]
    target_score = class_output[0, target_class]
    
    # Backward pass
    target_score.backward()
    
    # Get gradients
    gradients = input_tensor.grad
    
    if gradients is not None:
        # Simple attention map (sum of absolute gradients)
        attention_map = torch.sum(torch.abs(gradients), dim=1).squeeze()
        
        # Normalize
        attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())
        
        print(f"Attention map shape: {attention_map.shape}")
        print(f"Attention map range: [{attention_map.min():.3f}, {attention_map.max():.3f}]")
        print(f"Attention map mean: {attention_map.mean():.3f}")
        
        print("‚úì Grad-CAM test passed")
        return True
    else:
        print("‚úó Grad-CAM test failed: No gradients computed")
        return False


def test_integrated_gradients():
    """Test Integrated Gradients implementation."""
    print("\nTesting Integrated Gradients...")
    
    # Create model
    model = SimpleMultiTaskSwinUNETR()
    model.eval()
    
    # Create input and baseline
    input_tensor = torch.randn(1, 4, 96, 96, 96)
    baseline_tensor = torch.zeros_like(input_tensor)
    
    # Get target class
    with torch.no_grad():
        outputs = model(input_tensor)
        target_class = torch.argmax(outputs["classification"], dim=1).item()
    
    print(f"Target class: {target_class}")
    
    # Simple Integrated Gradients implementation
    num_steps = 10
    integrated_gradients = torch.zeros_like(input_tensor)
    
    for i in range(num_steps):
        alpha = i / num_steps
        interpolated = baseline_tensor + alpha * (input_tensor - baseline_tensor)
        interpolated.requires_grad_(True)
        
        # Forward pass
        outputs = model(interpolated)
        target_score = outputs["classification"][0, target_class]
        
        # Backward pass
        model.zero_grad()
        target_score.backward()
        
        # Accumulate gradients
        if interpolated.grad is not None:
            integrated_gradients += interpolated.grad / num_steps
    
    # Multiply by (input - baseline)
    integrated_gradients = integrated_gradients * (input_tensor - baseline_tensor)
    
    # Create attribution map
    attribution_map = torch.sum(torch.abs(integrated_gradients), dim=1).squeeze()
    
    print(f"Attribution map shape: {attribution_map.shape}")
    print(f"Attribution map range: [{attribution_map.min():.6f}, {attribution_map.max():.6f}]")
    print(f"Attribution map mean: {attribution_map.mean():.6f}")
    
    # Test convergence (simplified)
    with torch.no_grad():
        input_output = model(input_tensor)
        baseline_output = model(baseline_tensor)
        
        actual_diff = input_output["classification"][0, target_class] - baseline_output["classification"][0, target_class]
        approximated_diff = torch.sum(integrated_gradients)
        convergence_delta = torch.abs(actual_diff - approximated_diff).item()
    
    print(f"Convergence delta: {convergence_delta:.6f}")
    
    print("‚úì Integrated Gradients test passed")
    return True


def test_explainability_integration():
    """Test integration of both methods."""
    print("\nTesting explainability integration...")
    
    # Create model
    model = SimpleMultiTaskSwinUNETR()
    model.eval()
    
    # Create input
    input_tensor = torch.randn(1, 4, 96, 96, 96)
    
    # Test both methods
    gradcam_success = False
    ig_success = False
    
    try:
        # Test Grad-CAM
        input_tensor.requires_grad_(True)
        outputs = model(input_tensor)
        target_class = torch.argmax(outputs["classification"], dim=1).item()
        
        model.zero_grad()
        target_score = outputs["classification"][0, target_class]
        target_score.backward()
        
        if input_tensor.grad is not None:
            gradcam_success = True
            print("‚úì Grad-CAM integration successful")
        
    except Exception as e:
        print(f"‚úó Grad-CAM integration failed: {e}")
    
    try:
        # Test Integrated Gradients (simplified)
        input_tensor = torch.randn(1, 4, 96, 96, 96)  # Fresh tensor
        baseline_tensor = torch.zeros_like(input_tensor)
        
        # Simple 3-step integration
        integrated_gradients = torch.zeros_like(input_tensor)
        
        for i in range(3):
            alpha = i / 3
            interpolated = baseline_tensor + alpha * (input_tensor - baseline_tensor)
            interpolated.requires_grad_(True)
            
            outputs = model(interpolated)
            target_score = outputs["classification"][0, target_class]
            
            model.zero_grad()
            target_score.backward()
            
            if interpolated.grad is not None:
                integrated_gradients += interpolated.grad / 3
        
        ig_success = True
        print("‚úì Integrated Gradients integration successful")
        
    except Exception as e:
        print(f"‚úó Integrated Gradients integration failed: {e}")
    
    if gradcam_success and ig_success:
        print("‚úì Full explainability integration test passed")
        return True
    else:
        print("‚úó Explainability integration test failed")
        return False


def main():
    """Run all explainability tests."""
    print("=" * 60)
    print("NeuroDx-MultiModal Explainability Validation")
    print("=" * 60)
    
    try:
        # Test individual components
        gradcam_result = test_gradcam()
        ig_result = test_integrated_gradients()
        integration_result = test_explainability_integration()
        
        print("\n" + "=" * 60)
        print("VALIDATION SUMMARY")
        print("=" * 60)
        print(f"Grad-CAM: {'‚úì PASS' if gradcam_result else '‚úó FAIL'}")
        print(f"Integrated Gradients: {'‚úì PASS' if ig_result else '‚úó FAIL'}")
        print(f"Integration: {'‚úì PASS' if integration_result else '‚úó FAIL'}")
        
        if all([gradcam_result, ig_result, integration_result]):
            print("\nüéâ All explainability tests PASSED!")
            print("The explainability features are working correctly.")
            return True
        else:
            print("\n‚ùå Some explainability tests FAILED!")
            print("Please check the implementation.")
            return False
            
    except Exception as e:
        print(f"\nüí• Validation failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)